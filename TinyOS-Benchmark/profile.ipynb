{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- ./dataset/RadioSenseToLeds/3.txt ---------------\n",
      "[('0x000a', '0x0003', 14432), ('0x0000', '0x0004', 14432), ('0x0010', '0x0003', 14432), ('0x0002', '0x0004', 14432), ('0x0004', '0x000a', 14432), ('0x0004', '0x0010', 14433), ('0x0004', '0x0002', 14432), ('0x0004', '0x0003', 14432), ('0x0003', '0x0000', 14432), ('0x0003', '0x0004', 14432)] <class 'list'>\n",
      "\t\t\n",
      "debug <filter object at 0x7f307e560780>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "maxlag should be < nobs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-031f0bef7405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mhot_taskl_pair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoice_most_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_trans_fre_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhot_taskl_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhot_taskl_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_adf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhot_taskl_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhot_taskl_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0;31m#print tasks_sequence_split(range(12), 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-031f0bef7405>\u001b[0m in \u001b[0;36mcheck_adf\u001b[0;34m(tasks_queue, pre_task, next_task, block)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_serise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\\t\\ndebug\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob_serise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madfuller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob_serise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/statsmodels/tsa/stattools.py\u001b[0m in \u001b[0;36madfuller\u001b[0;34m(x, maxlag, regression, autolag, store, regresults)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mxdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mxdall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlagmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxdiff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'both'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'in'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mnobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxdall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=E1103\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/statsmodels/tsa/tsatools.py\u001b[0m in \u001b[0;36mlagmat\u001b[0;34m(x, maxlag, trim, original, use_pandas)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mdropidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaxlag\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mnobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"maxlag should be < nobs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m     \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnobs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmaxlag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnvar\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxlag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlag\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: maxlag should be < nobs"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "import statsmodels.tsa.stattools as ts\n",
    "\n",
    "class Goto(Exception):\n",
    "    pass\n",
    "\n",
    "def load_tasks_queque(fn):\n",
    "    \"\"\" loading tasks log from the fn file, watching log from Cooja.\n",
    "    and if it is the first load, log file will be store the pickle file for quick reading at next.\n",
    "    Args:\n",
    "        fn: str\n",
    "            name of log file from cooja\n",
    "        recompute: bool\n",
    "            if True, this will reload tasks log from log file from cooja, else from pickle file\n",
    "    Retval:\n",
    "        data: list\n",
    "            tasks queue like ['0x0001', '0x0002', '0x000a', ...]\n",
    "    \"\"\"\n",
    "        \n",
    "    with open(fn, 'r') as f:\n",
    "        #data = map(lambda e: re.findall('0x00[0-9a-f]{2}', e)[0], f.readlines())\n",
    "        def temp(e):\n",
    "            try:                \n",
    "                return re.findall('0x00[0-9a-f]{2}', e)[0]\n",
    "            except:\n",
    "                return None\n",
    "        data = map(temp, f.readlines())\n",
    "    return list(data)\n",
    "\n",
    "\n",
    "def occupy(ls, th=0.8):\n",
    "    \"\"\" Calculate how many items occupy the number over the total `th`*sum(ls) in `ls`\n",
    "    Args: \n",
    "        ls: list\n",
    "        th(threshold): folat\n",
    "    \"\"\"\n",
    "    assert len(ls) > 0, 'None of argument'\n",
    "    assert sum(ls) > 0, 'argument list was error %s' % str(ls)\n",
    "    ls = sorted(ls, reverse=True)\n",
    "    total = sum(ls)\n",
    "    count_sum = 0\n",
    "    for i in range(len(ls)):\n",
    "        count_sum += ls[i]\n",
    "        if float(count_sum) / total > 0.8:\n",
    "            return (float(i + 1) / len(ls), float(count_sum) / total)\n",
    "\n",
    "def get_trans_fre_mat(tasks_queue):\n",
    "    all_tasks = list(set(tasks_queue))\n",
    "    store = {e1: {e2:0 for e2 in all_tasks} for e1 in all_tasks}\n",
    "\n",
    "    for i in range(len(list(tasks_queue))-1):\n",
    "        store[tasks_queue[i]][tasks_queue[i+1]] += 1\n",
    "    return store\n",
    "\n",
    "    \n",
    "def occupy_feature(tasks_queue):\n",
    "    \"\"\" get \n",
    "    \"\"\"\n",
    "    all_tasks = list(set(tasks_queue))\n",
    "    store = get_trans_fre_mat(tasks_queue)\n",
    "\n",
    "    for i in range(len(tasks_queue)-1):\n",
    "        store[tasks_queue[i]][tasks_queue[i+1]] += 1\n",
    "    all_trans = sum(map(lambda e: sum(e.values()), store.values()))\n",
    "    \n",
    "    # weight of each task based on the number of execution\n",
    "    weights = {e: sum(store[e].values()) / float(len(tasks_queue)) for e in all_tasks}\n",
    "\n",
    "    occupy_data = {e: None for e in all_tasks}\n",
    "    for k, v in store.items():\n",
    "        try:\n",
    "            occupy_data[k] = occupy(v.values())\n",
    "        except AssertionError:\n",
    "            print('assert error')\n",
    "            return None\n",
    "            \n",
    "    #print occupy_data\n",
    "    task_proportion = sum(map(lambda kv: kv[1][0] * weights[kv[0]], occupy_data.items()))\n",
    "    occupy_precentage = sum(map(lambda kv: kv[1][1] * weights[kv[0]], occupy_data.items()))\n",
    "\n",
    "    ''' Based on mean value without weight\n",
    "    task_proportion = sum(map(lambda e: e[0], occupy_data.values())) / len(occupy_data.values())\n",
    "    occupy_proportion = sum(map(lambda e: e[1], occupy_data.values())) /  len(occupy_data.values())\n",
    "    '''\n",
    "    return {'task': task_proportion, 'occupy': occupy_precentage, \"tasks num\": len(all_tasks)}\n",
    "\n",
    "def tasks_sequence_split(tasks_sequence, n):\n",
    "    each_len = int(round(len(tasks_sequence) / float(n)))\n",
    "    return [tasks_sequence[i:i + each_len]\n",
    "            for i in range(0, len(tasks_sequence), each_len)]\n",
    "\n",
    "def choice_most_task(trans_mat, n):\n",
    "    # get n task pair, the number of trans is most\n",
    "    # fint hot pot task trans\n",
    "    temp = []\n",
    "    for e in trans_mat.values():\n",
    "        temp += e.values()\n",
    "    \n",
    "    temp = sorted(temp, reverse=True)\n",
    "    retval = []\n",
    "    for k, v in trans_mat.items():\n",
    "        for k2, v2 in v.items():\n",
    "            if v2 in temp[:n]: retval.append((k, k2, v2))\n",
    "    return retval\n",
    "    \n",
    "\n",
    "def check_adf(tasks_queue, pre_task, next_task, block=10):\n",
    "    all_tasks = list(set(tasks_queue))\n",
    "\n",
    "    splited_data = tasks_sequence_split(tasks_queue, block)\n",
    "    stores = map(lambda e: get_trans_fre_mat(e), splited_data)\n",
    "    #prob_trans = lambda e: float(e[pre_task][next_task])/ sum(e[pre_task].values())\n",
    "    def prob_trans(e):\n",
    "        if pre_task in e.keys():\n",
    "            if next_task in e[pre_task].keys():\n",
    "                if sum(e[pre_task].values()) > 0:\n",
    "                    return float(e[pre_task][next_task])/ sum(e[pre_task].values())\n",
    "        return None\n",
    "    prob_serise = map(prob_trans, stores)\n",
    "\n",
    "    # remove to those group(as a item in stores) have no `next_task ` or `pre_task`\n",
    "    prob_serise = filter(lambda e: e != None, prob_serise)\n",
    "    if len(list(prob_serise)) > 2:\n",
    "        print (\"\\t\\t\\ndebug\", prob_serise)\n",
    "        result =  ts.adfuller(list(prob_serise))\n",
    "        print(result)\n",
    "        return result\n",
    "    else:\n",
    "        print('No data')\n",
    "        return 'No data'\n",
    "    \n",
    "\n",
    "def conclusion(results):\n",
    "    cnt_1 = 0\n",
    "    cnt_5 = 0\n",
    "    cnt_10 = 0\n",
    "    results = filter(lambda e: e != 'No data', results)\n",
    "    for e in results:\n",
    "        print('debug 12', e[0], e[4]['1%'])\n",
    "        if float(e[0]) < float(e[4]['1%']):\n",
    "            cnt_1 += 1\n",
    "    try:\n",
    "        print('1%: ', float(cnt_1) / len(results), '\\ntotal: ', len(results))\n",
    "    except:\n",
    "        print('length of result is 0')\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ''' Zhang Te:\n",
    "    Do not touch anything !!!!\n",
    "    Only I am able to understand those codes. Contact me by paradoxt@gmail.com\n",
    "    '''\n",
    "    import tableprint as tp\n",
    "\n",
    "    results = []\n",
    "    for e1 in os.walk('./dataset'):\n",
    "        for e2 in e1[2]:\n",
    "            fn = os.path.join(e1[0], e2)\n",
    "            #if 'RadioCountToLeds1/2.txt' not in fn: continue\n",
    "            data = load_tasks_queque(fn)\n",
    "            if len(list(data)) < 2: continue\n",
    "            #result = occupy_feature(data)\n",
    "            #if result == None: continue\n",
    "            #print '-' * 60\n",
    "            #tp.banner(fn)\n",
    "            #tp.table([result.values()], result.keys())\n",
    "            print ('-' * 15, fn, '-' * 15)\n",
    "            hot_taskl_pair = choice_most_task(get_trans_fre_mat(data), 2)\n",
    "            print(hot_taskl_pair, type(hot_taskl_pair))\n",
    "            results.append(check_adf(data, hot_taskl_pair[0][0], hot_taskl_pair[0][1]))\n",
    "            #print tasks_sequence_split(range(12), 3)\n",
    "            print ('\\n\\n')   \n",
    "            #break # Only watch 1.txt from node 1\n",
    "    conclusion(results)\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
